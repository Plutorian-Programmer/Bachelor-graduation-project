{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "datapath = \"../data/data/v2.0/\"\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import seaborn as sn\n",
    "from numpy.random import default_rng\n",
    "from sklearn import tree\n",
    "import decisiontree as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dataframe = pd.read_csv(datapath+\"hipe2020/en/HIPE-2022-v2.0-hipe2020-dev-en.tsv\", sep = '\\t', header = 0, engine=\"python\", comment='#', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOKEN                       ar\n",
       "NE-COARSE-LIT                O\n",
       "NE-COARSE-METO               O\n",
       "NE-FINE-LIT                  _\n",
       "NE-FINE-METO                 _\n",
       "NE-FINE-COMP                 _\n",
       "NE-NESTED                    _\n",
       "NEL-LIT                      _\n",
       "NEL-METO                     _\n",
       "MISC              NoSpaceAfter\n",
       "SENTENCE_ID                  4\n",
       "Name: 98, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataframe.loc[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_sign = \"¬\"\n",
    "# del_list = []\n",
    "# english_dataframe = english_dataframe.copy()\n",
    "# for i in range(len(english_dataframe)):\n",
    "#     if english_dataframe.loc[i][\"MISC\"] == \"NoSpaceAfter\" and english_dataframe.loc[i+1][\"TOKEN\"] == combine_sign and english_dataframe.loc[i+1][\"MISC\"] == \"EndOfLine\":\n",
    "#         new_token = english_dataframe.loc[i][\"TOKEN\"] + english_dataframe.loc[i+2][\"TOKEN\"]\n",
    "#         english_dataframe.at[i,\"TOKEN\"] = new_token\n",
    "#         del_list += [i+1, i+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_dataframe.drop(index = del_list, inplace=True)\n",
    "# english_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "      <th>SENTENCE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>B-prod</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NIL</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MERCURY</td>\n",
       "      <td>I-prod</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NIL</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|EndOfSentence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>leading</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>principles</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>public</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0          From             O              O           _            _   \n",
       "1           the             O              O           _            _   \n",
       "2      AMERICAN        B-prod              O           _            _   \n",
       "3       MERCURY        I-prod              O           _            _   \n",
       "4             .             O              O           _            _   \n",
       "..          ...           ...            ...         ...          ...   \n",
       "100     leading             O              O           _            _   \n",
       "101  principles             O              O           _            _   \n",
       "102           ,             O              O           _            _   \n",
       "103        from             O              O           _            _   \n",
       "104      public             O              O           _            _   \n",
       "\n",
       "    NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                     MISC  \\\n",
       "0              _         _       _        _                        _   \n",
       "1              _         _       _        _                        _   \n",
       "2              _         _     NIL        _                        _   \n",
       "3              _         _     NIL        _             NoSpaceAfter   \n",
       "4              _         _       _        _  EndOfLine|EndOfSentence   \n",
       "..           ...       ...     ...      ...                      ...   \n",
       "100            _         _       _        _                        _   \n",
       "101            _         _       _        _             NoSpaceAfter   \n",
       "102            _         _       _        _                        _   \n",
       "103            _         _       _        _                        _   \n",
       "104            _         _       _        _                        _   \n",
       "\n",
       "     SENTENCE_ID  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "..           ...  \n",
       "100            4  \n",
       "101            4  \n",
       "102            4  \n",
       "103            4  \n",
       "104            4  \n",
       "\n",
       "[105 rows x 11 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe.head(n=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOKEN                arguments\n",
       "NE-COARSE-LIT                O\n",
       "NE-COARSE-METO               O\n",
       "NE-FINE-LIT                  _\n",
       "NE-FINE-METO                 _\n",
       "NE-FINE-COMP                 _\n",
       "NE-NESTED                    _\n",
       "NEL-LIT                      _\n",
       "NEL-METO                     _\n",
       "MISC              NoSpaceAfter\n",
       "SENTENCE_ID                  4\n",
       "Name: 98, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe.loc[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_list = english_dataframe[\"MISC\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_idx = []\n",
    "idx = 0\n",
    "for item in misc_list:\n",
    "    sentence_idx.append(idx)\n",
    "    if \"EndOfSentence\" in item:\n",
    "        idx += 1\n",
    "english_dataframe[\"SENTENCE_ID\"] = sentence_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_sentences = set()\n",
    "for i, label in enumerate(english_dataframe[\"NE-COARSE-LIT\"].to_list()):\n",
    "    if label != \"O\":\n",
    "        labelled_sentences.add(sentence_idx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = english_dataframe[\"TOKEN\"].str.lower().value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_dict = english_dataframe[english_dataframe[\"NE-COARSE-LIT\"] != \"O\"][\"TOKEN\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14543\n",
      "[',', 'the', '.', 'of', 'and', 'to', 'a', '¬', 'in', 'is', '-', 'that', 'for', 'he', 'be', 'as', 'was', 'it', 'at', 'on', 'by', 'with', 'this', 'will', 'have', 'from', '’', 'his', 'are', 'i', 'their', ';', 'which', 's', 'not', 'they', '*', 'has', '“', \"'\", 'you', 'an', 'or', 'one', 'all', '”', 'we', 'been', 'but', 'no', 'who', 'than', 'our', 'were', 'other', '—', 'county', 'any', 'them', 'made', 'when', 'man', 'more', 'new', 'there', 'out', 'can', 'j', 'may', 'day', 'would', 'its', ':', 'had', '(']\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "total_word_count = len(english_dataframe)\n",
    "total = 0\n",
    "for key in token_dict:\n",
    "    total += token_dict[key]\n",
    "    feature_list.append(key)\n",
    "    if total > total_word_count * 0.5:\n",
    "        break\n",
    "print(total)\n",
    "print(feature_list)\n",
    "print(len(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_fix_dict_3 = defaultdict(lambda:0)\n",
    "post_fix_dict_2 = defaultdict(lambda:0)\n",
    "post_fix_3_list = []\n",
    "post_fix_2_list = []\n",
    "for key in token_dict:\n",
    "    if key == \"endofsentence\":\n",
    "        continue\n",
    "    if len(key) <= 2:\n",
    "        continue\n",
    "    count = token_dict[key]\n",
    "    \n",
    "    if len(key) == 3:\n",
    "        post_fix_2 = key[-2:]\n",
    "        post_fix_dict_2[post_fix_2] += count\n",
    "        if post_fix_dict_2[post_fix_2] >= 30 and post_fix_2 not in post_fix_2_list:\n",
    "            post_fix_2_list.append(post_fix_2)\n",
    "        continue\n",
    "\n",
    "    post_fix_3 = key[-3:]\n",
    "    post_fix_dict_3[post_fix_3] += count\n",
    "    if post_fix_dict_3[post_fix_3] >= 30 and post_fix_3 not in post_fix_3_list:\n",
    "            post_fix_3_list.append(post_fix_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list =  list(pd.unique(english_dataframe[\"NE-COARSE-LIT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = []\n",
    "label_matrix = []\n",
    "pos_dict = defaultdict(lambda: [])\n",
    "label_dict = defaultdict(lambda: [])\n",
    "pos = 0\n",
    "progress = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "prev_label = 0\n",
    "extra_features = 6\n",
    "check = True\n",
    "for idx in english_dataframe.index:\n",
    "    if idx/len(english_dataframe) > progress[0]:\n",
    "        print(progress[0])\n",
    "        progress.pop(0)\n",
    "    pos += 1\n",
    "    row = english_dataframe.iloc[idx]\n",
    "    token = row[\"TOKEN\"]\n",
    "    if isinstance(token, float): #null in the tsv is taken as a nan value\n",
    "        token = \"null\"\n",
    "    prev_label = label\n",
    "    label = int(row[\"NE-COARSE-LIT\"] != \"O\")\n",
    "    if token.lower() in feature_list:\n",
    "        pos_dict[token.lower() ].append(pos)\n",
    "    if \"EndOfSentence\" not in row[\"MISC\"]:\n",
    "        label_dict[token].append((pos,label,prev_label,0))\n",
    "        continue\n",
    "    label_dict[token].append((pos,label,prev_label,1))\n",
    "    # loop of all tokens in a sentence\n",
    "    for token in label_dict:\n",
    "        # loop over all ocurances of a token\n",
    "        for item in label_dict[token]:\n",
    "            feature_vector = np.zeros(shape = (len(feature_list)+extra_features)) #differntiate between wheter a token occurs or wheter the current token is in the top 50%\n",
    "            # label_vector = np.zeros(shape=(2))\n",
    "            current_pos = item[0]\n",
    "            \n",
    "            # loop over all features present in a sentence\n",
    "            for feature in pos_dict:\n",
    "                closest_pos = pos_dict[feature][0] - current_pos # starting point\n",
    "                \n",
    "                # loop over all occurences of a feature present in a sentence\n",
    "                for pos in pos_dict[feature]:\n",
    "                    relative_pos = pos - current_pos\n",
    "                    if abs(relative_pos) < abs(closest_pos):\n",
    "                        closest_pos = relative_pos\n",
    "                    else: break\n",
    "                feature_vector[feature_list.index(feature)] = closest_pos\n",
    "            feature_vector[-1] = item[0] # add location as feature\n",
    "            feature_vector[-2] = item[3] # add wheter the item is the end of a sentence\n",
    "            feature_vector[-3] = int(token[0].isupper()) #add wheter the first char is a capital letter\n",
    "            feature_vector[-4] = int(any(char.isdigit() for char in token))\n",
    "            \n",
    "            if len(token) > 3:\n",
    "                post_fix = token[-3:].lower()\n",
    "                if post_fix in post_fix_3_list:\n",
    "                    feature_vector[-5] = post_fix_3_list.index(post_fix) + 1\n",
    "                    check = False\n",
    "                # print(post_fix)\n",
    "            if len(token) > 2:\n",
    "                post_fix = token[-2:].lower()\n",
    "                if post_fix in post_fix_2_list:\n",
    "                    feature_vector[-6] = post_fix_2_list.index(post_fix) + 1\n",
    "                # print(post_fix)\n",
    "            # if not check:\n",
    "            #     print(token)\n",
    "            #     break\n",
    "            feature_matrix.append(feature_vector)\n",
    "            # label_vector[item[1]] = 1\n",
    "            label_matrix.append(item[1])\n",
    "    # break\n",
    "    pos = 0\n",
    "    pos_dict = defaultdict(lambda: [])\n",
    "    label_dict = defaultdict(lambda: [])\n",
    "    prev_label = 0\n",
    "feature_matrix = np.array(feature_matrix)\n",
    "label_matrix = np.array(label_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = len(set(sentence_idx))\n",
    "split = 0.5\n",
    "rng = default_rng()\n",
    "training_sentence_ids = rng.choice(total_sentences, size=int(total_sentences*split), replace=False)\n",
    "test_sentence_ids = [i for i in range(total_sentences) if i not in training_sentence_ids]\n",
    "\n",
    "training_id_list = []\n",
    "test_id_list = []\n",
    "for i, item in enumerate(sentence_idx):\n",
    "    if item in training_sentence_ids:\n",
    "        training_id_list.append(i)\n",
    "    else:\n",
    "        test_id_list.append(i)\n",
    "\n",
    "training_feature_matrix = np.array([feature_matrix[i] for i in training_id_list])\n",
    "training_label_matrix = np.array([label_matrix[i] for i in training_id_list])\n",
    "test_feature_matrix = np.array([feature_matrix[i] for i in test_id_list])\n",
    "test_label_matrix = np.array([label_matrix[i] for i in test_id_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14663, 81)\n"
     ]
    }
   ],
   "source": [
    "print(training_feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = training_feature_matrix.shape[1]\n",
    "discrete_idx_list = [total_features-2, total_features-3, total_features-4, total_features-5, total_features-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79, 78, 77, 76, 75]\n"
     ]
    }
   ],
   "source": [
    "print(discrete_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "test_classifier = dt.custom_decision_tree(training_feature_matrix, training_label_matrix, discrete_idx_list=discrete_idx_list, min_samples=35)\n",
    "test_classifier.build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tree = test_classifier.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: 78\n",
      "best guess: 0\n",
      "entropy: 0.4381362130723046\n",
      "split values [0.0, 1.0]\n",
      "type: discrete\n",
      "child value: 0.0    child branch feature: 76\n",
      "child value: 1.0    child branch feature: 76\n"
     ]
    }
   ],
   "source": [
    "custom_tree.print_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9077432255395436\n",
      "recall: 0.337295690936107\n",
      "precision: 1.0\n",
      "f_1: 0.5044444444444445\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "total = 0\n",
    "prediction = custom_tree.predict_matrix(test_feature_matrix)\n",
    "prev_label = 0\n",
    "for i, pred in enumerate(prediction):\n",
    "    correct_label = test_label_matrix[i]\n",
    "    if correct_label == 0 and pred == 0:\n",
    "        tn += 1\n",
    "    elif correct_label == 0 and pred != 0:\n",
    "        fn += 1\n",
    "    elif correct_label == 1 and pred == 0:\n",
    "        fn += 1\n",
    "    else:\n",
    "        tp += 1\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f_1 = (2*precision*recall)/(precision+recall)\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\" )\n",
    "print(f\"f_1: {f_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0})\n",
    "wrong_pred_dict = defaultdict(lambda:[])\n",
    "correct_pred_dict = defaultdict(lambda:[])\n",
    "for i, pred in enumerate(prediction):\n",
    "    id = test_id_list[i]\n",
    "    label = english_dataframe.iloc[id][\"NE-COARSE-LIT\"]\n",
    "    token = english_dataframe.iloc[id][\"TOKEN\"]\n",
    "    if label == \"O\" and pred == 0:\n",
    "        test_dict[\"O\"][\"tp\"] += 1\n",
    "    elif label == \"O\" and pred == 1:\n",
    "        test_dict[\"O\"][\"fn\"] += 1\n",
    "    elif label != \"O\" and pred == 0:\n",
    "        test_dict[label][\"fn\"] += 1\n",
    "        test_dict[\"O\"][\"fp\"] += 1\n",
    "        wrong_pred_dict[label].append(token)\n",
    "    elif label != \"O\" and pred == 1:\n",
    "        test_dict[label][\"tp\"] += 1\n",
    "        test_dict[\"O\"][\"tn\"] += 1\n",
    "        correct_pred_dict[label].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-prod\n",
      "['anti', 'anti', 'GAZETTE', 'MAGNA', 'A', 'Winy', 'Obseiver', 'Fayetteville', 'Wilmington', 'the', 'Weld', 'Putnam', 'Norfolk', 'Guide', 'Christian']\n",
      "------------------------------------\n",
      "I-prod\n",
      "['-', 'federalifm', '-', 'federalifm', 'Gaz', 'CHARTA', 'SPLENDID', 'EDITION', 'OF', 'THE', 'Declaration', 'of', 'Independence', 'aw', '.', 'Observer', '-', 'xertiscr', 'Journal', 'Alkkt', 'County', 'Republican', 'ald', '¬', 'azine', 'and', 'Guide', 'Science', 'Science']\n",
      "------------------------------------\n",
      "B-loc\n",
      "['Point', 'Guadaloupe', 'Point', 'America', 'Bengal', 'Bra', 'Brabant', 'Breda', 'Genoa', 'Genoa', 'Milford', 'State', 'Philadelphia', 'VIENNA', 'Vienna', 'Br.iuniu', 'Braunao', 'England', 'Frtnce', 'London', 'Dublin', 'Wilmington', 'Malta', 'Biistol', 'Cape', 'loGibraltar', 'Cagliari', 'Port', 'L', 'United', 'Paris', 'Portugal', 'Spain', 'Portugal', 'Lisbon', 'United', 'Virginia', 'lit', 'Sciota', 'Christ', 'Alexandria', 'the', 'Piince', 'America', 'Europe', 'Ireland', 'Pomonkey', 'Charles', 'Maryland', 'Mount', 'BaltimorCy', 'Margaritta', 'Georgetown', 'Rambouillet', 'Baltimore', 'Baltimore', 'Baltimore', 'Gates', 'Court', 'Gatesville', 'United', 'United', 'northern', 'Colorado', 'Lose', 'TERRITORY', 'Stutsman', 'New', 'the', 'Washington', 'K', 'Wichita', 'Kiowa', 'Germany—one', 'THE', 'Wright', 'Tacotna', 'Portland', 'Lewiston', 'Marshal', 'the', 'Spokane', 'Basin', 'America', 'Chicago', 'upper', 'Cookeville', 'Nashville', 'Jerusalem', 'Egypt', 'Jerusalem', 'Jeru', 'Gainesboro', 'Main', 'NashvUle', 'Cookeville', 'United', 'ROME', 'Italy', 'Italy', 'Italy', 'an', 'Rome', 'Mich', 'Isabella', 'Midland', 'Gladwin', 'Monroe', 'Wayne', 'Huron', 'Arenac', 'Alpena', 'Presque', 'Cheboygan', 'Charlevoi', 'Upper', 'Michigan', 'Oshima', 'Norfolk', 'Columbia', 'hSelby', 'White', 'Highland', 'Valley', 'Tabor', 'Pensacola', 'Mediterranean', 'Dillon', '’']\n",
      "------------------------------------\n",
      "I-loc\n",
      "['Petre', 'a', 'Petre', 'a', 'Petre', '¬', 'bant', '*', 'county', 'of', 'Rboda', '-', 'Island', 'Alarket', '-', 'Jlreet', '.', 'Mahon', 'ondon', 'States', '-', 'States', 'of', 'America', '¬', 'tle', 'Miami', 'U', '.', 'S', '.', 'YV', 'illiam', 'House', 'county', '-', 'street', 'Carolina', 'county', 'House', 'Dakota', 'Tree', 'county', 'York', '.', 'U', 'S', '.', 'Fe', ',', 'N', '.', 'M', '-', 'wood', 'county', '.', 'Louis', '^', 'iotua', 'NORTHWEST', 'park', ',', 'Junction', 'Yak', '¬', 'ima', 'Indian', 'reservation', '.', 'O', '.', 'hall', 'section', ',', 'salem', 'street', 'ville', 's', '¬', 'cient', 'Rome', '¬', 'Isle', '*', 'Peninsula', 'Or', '¬', 'leans', 'Island', ',', '.', 'Tennessee', 'House', ',', 'Del', '.', '.', '.', 'Woodward', 'Thurman', '569', 'East', '¬', 'tion', '.', 'county', '’', \"'\", 'bor']\n",
      "------------------------------------\n",
      "B-org\n",
      "['France', 'the', 'France', 'Austrian', 'the', 'the', 'French', 'British', 'House', 'War', 'France', 'England', 'Portugal', 'Denmark', 'Union', 'Little', 'office', 'the', 'General', 'North', 'Bucklen', 'Hart', 'Stephens', 'The', 'the', 'the', 'the', 'Masonic', 'Mattie', 'American', 'Pullman', 'Cookeville', 'Woman', 'Russia', 'Wayne', 'Birdland', 'Bop', 'National', 'United', 'YWCA']\n",
      "------------------------------------\n",
      "I-org\n",
      "['United', 'States', 'of', 'America—And', 'Army', 'of', 'Health', 'College', 'Board', 'army', 'army', 'ot', 'War', '§', 'f', 'Representatives', 'Depart', '¬', 'ment', '¬', 'andria', 'turnpike', 'company', 'ol', 'Discount', 'and', 'Deposit', 'Crown', 'Gov', '¬', 'ernment', 'Caro', '¬', 'lina', ',', 'Schafiner', '&', 'Clothing', '&', '’', 'Union', 'veterans', 'Union', 'nation', 'post', 'office', 'department', 'j', '.', 'chandise', 'books', 'periodicals', 'fra', '¬', 'ternities', 'Colfax', 'Ferguson', 'Association', 'Organists', 'Kimball', 'Co', 'Chamber', 'Commerce', 'Mills', \"'\", 's', 'Battalion', 'Death', 'City', 'Nations']\n",
      "------------------------------------\n",
      "B-time\n",
      "['18th', 'years', 'July', 'November', '1559', '6th', 'August', 'in']\n",
      "------------------------------------\n",
      "I-time\n",
      "['February', '1199', 'and', '1802', '9,1800', '23', ',', '1', '80s', 'December', ',', '1829', ',', ',', '1830', 'of', 'May', ',', '1840', '13', ',', '1800', 'nessee']\n",
      "------------------------------------\n",
      "I-pers\n",
      "[',', 'Cadiot', 'Lombard', 'Rebian', 'd', '’', ',', 'prelident', 'of', 'the', 'war', 'department', 'Schon', '-', 'feld', 'd', '’', 'Ahreniberg', 'de', 'laMarck', 'Lewis', 'd', \"'\", 'Ahreinberg', 'd', '’', 'Urfe', '-', 'gerloo', 'Van', 'der', 'Majefty', 'BRINK', ',', 'Esquire', 'Kellogg', ',', '.', 'Duroc', 'St', '.', '-', 'Julien', \"'\", 'an', 'Plen', '-', '*', 'DAVIS', '.', '.', 'Dr', '.', 'Bigelow', '.', '7', 'AK', 'Johnson', 'Bounds', '.', 'B', '.', 'Fain', 'li', '.', 'of', 'the', 'House', 'of', ',', 'Vice', 'President', 'of', 'the', 'United', 'Slates', ',', 'and', 'the', 'England', 'Mary', 'of', 'and', 'patiiarch', 'Coke', ',', '.', '.', 'Phillips', 'Ferguson', '’', 'Weaver', '\\\\', 'llister', '.', 'honor', 'Judge', 'Bland', 'gucl', 'DANIEL', 'King', 'Duke', 'of', 'Orleans', ',', 'Lieu', '¬', 'General', 'of', 'the', 'Kingdom', 'de', 'Bor', '¬', 'deaux', 'Dauphin', 'V', 'of', 'France', 'V', 'Vis', '¬', 'count', 'do', 'Foissac', 'Latour', '.', '“', 'LOUIS', '.', '.', 'ings', ',', 'Esq', ',', 'R', '.', 'Rawles', 'H', '.', 'Harrison', 'K', '.', 'Polk', 'Tennessee', '.', 'Cowper', '-', 'mell', 'Stallings', 'Riddick', 'Daughtry', 'Parker', 'Riddick', 'Walters', '.', 'Riddick', '.', 'Jones', 'Norfleet', 'Norfleet', '¬', 'Hill', '.', 'Stallings', ',', 'Esq', 'COWPER', '.', 'Secretary', '.', 'Spencer', 'Gilmore', '.', 'Ketchum', 'Ketchum', 'States', 'Marshal', 'A', '.', 'Thompson', '.', 'W', '.', 'Nnclien', 'the', 'rural', 'delivery', 'system', 'E', '.', 'O', '.', 'Wolcott', ',', 'special', 'agent', 'of', 'rural', 'free', 'delivery', 'Rluer', 'Marshall', '’', '.', 'May', 'Struppler', '.', 'Matt', 'arson', '.', 'Matterson', 'Taft', 'T', '.', 'Bloni', '.', 'Wendell', 'Ellis', 'Jeakel', '.', 'A', '.', 'A', '’', 'oung', 'and', 'Mrs', 'II', 'Canfield', 'Canfield', '.', 'Hildebrant', '.', 'John', 'J', 'or', '¬', 'ganist', 'of', 'the', 'Mormon', 'Tabernacle', 'at', 'Salt', '.', 'Mc', 'Clellan', 'Hargis', '.', 'S', '.', 'Hargis', 'Leona', 'Byrne', '.', 'O', '.', 'Martin', '.', 'Farley', '.', 'Farley', 'Rawley', 'Lee', 'Maddux', '.', 'Curie', 'Curie', 'aheth', 'City', \"'\", 'strong', '-', 'headed', 'Trial', '.', '.', '.', 'King', 'Roddy', 'Ingram', 'Ann', ',', 'Franklin', 'S', '.', 'and', 'Sts', '-', '.', 'L', '.', '.']\n",
      "------------------------------------\n",
      "B-pers\n",
      "['Baron', 'Duke', 'Count', 'Prince', 'Duke', 'Major', 'his', 'theFmperor', 'Melas', 'Berthicr', 'JOHN', 'Citizen', 'Duroc', 'Auff.x', 'GEORGE', 'Mr', 'Rev', 'Mr', 'Dr', 'ROBERT', 'captain', 'Capt', 'captain', 'captain', 'Burr', 'Bonaparte', 'capt', 'Gen', 'George', 'queen', 'doge', 'thedukeof', 'Loid', 'William', 'Thomas', 'Charles', 'Isaac', 'bis', 'JOHN', 'Ferdinand', 'Don', 'the', 'the', 'Duke', 'Tile', 'King', 'Henry', 'CHARLES', 'Gen', 'Harri', 'W', 'Chairman', 'William', 'James', 'Riddick', 'John', 'Simon', 'John', 'Riddick', 'Marmaduke', 'Seth', 'Red', 'John', 'YVhitmell', 'General', 'Mr', 'Pat', 'Harry', '0', 'Judge', 'Tom', 'Tom', 'United', 'Tom', 'Tom', 'Tom', 'A', 'Senator', 'Judge', 'Judge', 'Decovi', 'Garfield', 'Harrison', 'McKinley', 'Miss', 'A', 'President', 'Myrtle', 'Laura', 'Charles', 'Jeakel', 'Judge', 'Judge', 'H', 'Mrs', 'Moses', 'Mr', 'Mr', 'D', 'Bob', 'Alfred', 'Madam', 'Madam', 'EHz', 'W', 'the', 'Mussolini', 'Mussolini', 'Joseph', 'Mary', 'Mrs', 'Jesus', 'God']\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for label in wrong_pred_dict:\n",
    "    print(label)\n",
    "    print(wrong_pred_dict[label])\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-prod\n",
      "0.21052631578947367\n",
      "------------------------\n",
      "I-prod\n",
      "0.275\n",
      "------------------------\n",
      "B-loc\n",
      "0.3316062176165803\n",
      "------------------------\n",
      "I-loc\n",
      "0.38202247191011235\n",
      "------------------------\n",
      "B-org\n",
      "0.23076923076923078\n",
      "------------------------\n",
      "I-org\n",
      "0.24731182795698925\n",
      "------------------------\n",
      "B-time\n",
      "0.2727272727272727\n",
      "------------------------\n",
      "I-time\n",
      "0.20689655172413793\n",
      "------------------------\n",
      "B-pers\n",
      "0.4175257731958763\n",
      "------------------------\n",
      "I-pers\n",
      "0.35947712418300654\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in test_dict:\n",
    "    if key == \"O\":\n",
    "        continue\n",
    "    print(key)\n",
    "    temp_tp = test_dict[key]['tp']\n",
    "    temp_fn = test_dict[key][\"fn\"]\n",
    "    print(temp_tp/(temp_tp+temp_fn))\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "0.1\n",
      "0.2\n",
      "0.3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-4537aa8fe5c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtest_label_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_id_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtest_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_feature_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_label_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_idx_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiscrete_idx_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mtest_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mcustom_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_node\u001b[1;34m(self, idx_list, node, feature_idx_list)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabaled_idx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_labels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_node\u001b[1;34m(self, idx_list, node, feature_idx_list)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabaled_idx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_labels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_node\u001b[1;34m(self, idx_list, node, feature_idx_list)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabaled_idx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_labels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_node\u001b[1;34m(self, idx_list, node, feature_idx_list)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabaled_idx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_labels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_node\u001b[1;34m(self, idx_list, node, feature_idx_list)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mtemp_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_feature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabaled_idx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_labels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mbuild_node\u001b[1;34m(self, idx_list, node, feature_idx_list)\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabaled_idx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mtemp_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInfo_gain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_best_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_idx_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_idx_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[0mtemp_feature_idx_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_idx_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnode_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"leaf\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mfind_best_split\u001b[1;34m(self, idx_list, feature_idx_list)\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0mnode_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"discrete\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                 \u001b[0mInfo_gain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinious_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[0mnode_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"continious\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mInfo_gain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_ig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mcontinious_gain\u001b[1;34m(self, feature_idx, idx_list)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcontinious_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# best_weighted_entropy = entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\karst\\OneDrive\\Documenten\\uni\\jaar 3 semester 2, het semester dat ik opgaf\\Bachelor-graduation-project\\code\\notebooks\\decisiontree.py\u001b[0m in \u001b[0;36mcalc_entropy\u001b[1;34m(self, idx_list)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mbest_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we know that temp labels is all zeros or all ones, if 1 in temp labels it is true so it should be 1 else it should be 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mpositive_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mnegative_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpositive_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnegative_prob\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpositive_prob\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_itterations = 1\n",
    "performance_dict = defaultdict(lambda:{\"avg_prec\":0, \"avg_recall\": 0, \"avg_acc\": 0, \"avg_f1\":0})\n",
    "recall_dict =  defaultdict(lambda: defaultdict(lambda:0))\n",
    "\n",
    "for prob in np.arange(0.1, 1, step=0.1):\n",
    "    for itter in range(total_itterations):\n",
    "        total_sentences = len(set(sentence_idx))\n",
    "        split = prob\n",
    "        rng = default_rng()\n",
    "        training_sentence_ids = rng.choice(total_sentences, size=int(total_sentences*split), replace=False)\n",
    "        test_sentence_ids = [i for i in range(total_sentences) if i not in training_sentence_ids]\n",
    "\n",
    "        training_id_list = []\n",
    "        test_id_list = []\n",
    "        for i, item in enumerate(sentence_idx):\n",
    "            if item in training_sentence_ids:\n",
    "                training_id_list.append(i)\n",
    "            else:\n",
    "                test_id_list.append(i)\n",
    "\n",
    "        training_feature_matrix = np.array([feature_matrix[i] for i in training_id_list])\n",
    "        training_label_matrix = np.array([label_matrix[i] for i in training_id_list])\n",
    "        test_feature_matrix = np.array([feature_matrix[i] for i in test_id_list])\n",
    "        test_label_matrix = np.array([label_matrix[i] for i in test_id_list])\n",
    "        test_classifier = dt.custom_decision_tree(training_feature_matrix, training_label_matrix, discrete_idx_list=discrete_idx_list, min_samples=35)\n",
    "        test_classifier.build_tree()\n",
    "\n",
    "        custom_tree = test_classifier.tree\n",
    "        \n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        total = 0\n",
    "        prediction = custom_tree.predict_matrix(test_feature_matrix)\n",
    "        prev_label = 0\n",
    "        temp_dict = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0})\n",
    "        for i, pred in enumerate(prediction):\n",
    "            correct_label = test_label_matrix[i]\n",
    "            id = test_id_list[i]\n",
    "            label_txt = english_dataframe.iloc[id][\"NE-COARSE-LIT\"]\n",
    "            if correct_label == 0 and pred == 0:\n",
    "                tn += 1\n",
    "            elif correct_label == 0 and pred != 0:\n",
    "                fn += 1\n",
    "            elif correct_label == 1 and pred == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "            \n",
    "            if label_txt == \"O\" and pred == 0:\n",
    "                temp_dict[\"O\"][\"tp\"] += 1\n",
    "            elif label_txt == \"O\" and pred == 1:\n",
    "                temp_dict[\"O\"][\"fn\"] += 1\n",
    "            elif label_txt != \"O\" and pred == 0:\n",
    "                temp_dict[label_txt][\"fn\"] += 1\n",
    "                temp_dict[\"O\"][\"fp\"] += 1\n",
    "            elif label_txt != \"O\" and pred == 1:\n",
    "                temp_dict[label_txt][\"tp\"] += 1\n",
    "                temp_dict[\"O\"][\"tn\"] += 1\n",
    "        \n",
    "        if tp == 0:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "        else:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        f_1 = (2*precision*recall)/(precision+recall)\n",
    "        performance_dict[prob][\"avg_prec\"] += precision/total_itterations\n",
    "        performance_dict[prob][\"avg_recall\"] += recall/total_itterations\n",
    "        performance_dict[prob][\"avg_acc\"] += accuracy/total_itterations\n",
    "        performance_dict[prob][\"avg_f1\"] += f_1/total_itterations\n",
    "\n",
    "        for key in temp_dict:\n",
    "            tp = temp_dict[key][\"tp\"]\n",
    "            fn = temp_dict[key][\"fn\"]\n",
    "            if tp == 0:\n",
    "                recall = 0\n",
    "            else:\n",
    "                recall = tp/(tp+fn)\n",
    "            recall_dict[prob][key] += recall / total_itterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_prec': 1.0, 'avg_recall': 0.2821755519655358, 'avg_acc': 0.897232287410377, 'avg_f1': 0.4401511969760605}\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for key in performance_dict:\n",
    "    print(performance_dict[key])\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda>.<locals>.<lambda> at 0x000002421B6BADC8>, {'O': 0.9128054891681443})\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for key in recall_dict:\n",
    "    print(recall_dict[key])\n",
    "    print(\"----------------\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d583cb8ff8cf199ca57f0ebad24d1eeeb4706b5656d42d5fea7312fa19d29df"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
